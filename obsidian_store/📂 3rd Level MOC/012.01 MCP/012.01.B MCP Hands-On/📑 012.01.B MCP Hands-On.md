links: [[🌐 000 MKH Home]] | [[📖 010 Themes]] | [[📚 012 Topics]] | [[📂 3rd Level MOC/012.01 MCP/📗 012.01 MCP]]

Links: 
- [Teddy Note Notion - MCP](https://teddylee777.notion.site/MCP-1c424f35d129802e998de5301edf1069)
- [Langchain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)
- [Langchain mcpdoc](https://github.com/langchain-ai/mcpdoc/tree/main)
- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)

## MCP 통신 방식에 따른 MCP server/client 구성
### SSE
``` python
# mcp_server_sse.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP(
	# Name of the MCP server
	"Weather",
	# LLM instructions for using the tool
	instructions = "You are a weather assistant that can answer questions about the weather in a given location",
	# Host address (0.0.0.0 allows connections from all IPs)
	host="0.0.0.0",
	# Port Number for the server
	port=8005,
)

@mcp.tool()
async def get_weather(location: str) -> str:
	"""
	Get current weather information for the specified location.

	Args:
		location (str): The name of the location

	Returns:
		str: A string containing weather info.
	"""
	return f"It's always Sunny in {location}"

if __name__ == "__main__":
	mcp.run(transport="sse")

```
#### Client
```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

async with MultiServerMCPClient(
	{
		"docs": {
			"url": "http://localhost:8005/sse",
			"transport": "sse"
		}
	}
) as client:
	agent = create_react_agent(model, client.get_tools())
	answer = await astream_graph_custom(agent, {"messages": "서울의 날씨는 어떠니?"})
```
>>> (답변은 아래 stdio 에서 확인)
### Stdio(Local) 
#### Server
``` python
# mcp_server_stdio.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP(...)

@mcp.tool()
async def get_weather(location: str) -> str:
	...

if __name__ == "__main__":
	mcp.run(transport="stdio")
```
#### Client
```python
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langgraph.prebuilt import create_react_agent
from langchain_mcp_adapters.tools import load_mcp_tools

server_params = StdioServerParameters(
	command"./.venv/bin/python",
	args=["mcp_server_stdio.py"],
)

async with stdio_client(server_params) as (read,write):
	# 클라이언트 세션 생성
	async with ClientSession(read, write) as session:
		# 연결 초기화
		await session.initialize()
		# MCP 도구 로드
		tools = await load_mcp_tools(session)
		# 에이전트 생성
		agent = create_react_agent(model, tools)
		# 에이전트 응답 스트리밍
		await astream_graph_custom(
			agent,
			{"messages": "서울의 날씨는 어떠니?"},
			stream_mode="updates" # REACT 에이전트는 updates 모드가 적합
		)

```
>>>
``` 
[StructuredTool(name='get_weather', description='\n    Get current weather information for the specified location.\n\n    Args:\n        location (str): The name of the location (city, region, etc.) to get weather for\n\n    Returns:\n        str: A string containing weather information for the specified location\n    ', args_schema={'properties': {'location': {'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact']

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
🔹 노드: agent
┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄
도구 호출: [{'name': 'get_weather', 'args': {'location': '서울'}, 'id': 'call_6LvpzhhIYPClBwkQvK8w7NtW', 'type': 'tool_call'}]

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
🔹 노드: tools
┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄
도구 결과: It's always Sunny in 서울

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
🔹 노드: agent
┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄┄
응답: 서울은 항상 맑은 날씨라고 하네요! 다른 궁금한 점이 있으신가요?
```


References:
- [Teddy Note Notion - MCP](https://teddylee777.notion.site/MCP-1c424f35d129802e998de5301edf1069)
- [Langchain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)
- [Langchain mcpdoc](https://github.com/langchain-ai/mcpdoc/tree/main)
- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)
- [fastmcp](https://github.com/jlowin/fastmcp)

